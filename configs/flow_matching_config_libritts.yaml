trainer:
  resume: false
  checkpoint: null

  min_lr: 1e-6
  learning_rate: 2e-4
  weight_decay: 0.01
  grad_clip: 1.0
  epochs: 200
  log_interval: 100
  val_interval: 5000
  save_interval: 10000
  output_dir: "output/flow_matching_4GPUs_flowvae_330000_feat"

dataset:
  train_file_list: "data/libritts/libritts_train_bk.txt"
  valid_file_list: "data/libritts/libritts_valid_bk.txt"
  tokenizer_file: "checkpoints/xtts2/vocab.json"
  sample_rate: 22050
  num_workers: 16
  batch_size: 16

  min_conditioning_duration: 3.0 # 3s
  max_conditioning_duration: 6.0 # 6s
  min_audio_duration: 0.5
  max_audio_duration: 15.0
  min_text_length: 1.0
  max_text_length: 300

  use_masking_gt_prompt_approach: true

model:
  vq_vae:
    config: "configs/vq_vae_config_libritts_ft.yaml"
    checkpoint: "checkpoints/xtts2/dvae.pth"
    mel_norm_file: "checkpoints/xtts2/mel_stats.pth"

  gpt:
    config: "configs/gpt_config_libritts_ft.yaml"
    checkpoint: "checkpoints/xtts2/gpt.pth"

  flow_vae:
    config: "configs/flow_vae_config_libritts.yaml"
    checkpoint: "output/flow_vae_22050_4GPUs_dim80/checkpoint_330000.pth"
    
  flow_matching: # https://github.com/FunAudioLLM/CosyVoice/blob/main/examples/libritts/cosyvoice/conf/cosyvoice.yaml
    input_size: 512 # vq token embedding size
    output_size: 256 # vq token embedding proj & speaker embd output size
    spk_embed_dim: 1024 # speaker embd input size
    vocab_size: 4096
    only_mask_loss: True
    encoder:
      input_size: 512 # vq token encoder input size
      output_size: 512 # vq token encoder output size
      attention_heads: 8
      linear_units: 2048
      num_blocks: 6
      dropout_rate: 0.1
      positional_dropout_rate: 0.1
      attention_dropout_rate: 0.1
      normalize_before: True
      input_layer: 'linear'
      pos_enc_layer_type: 'rel_pos_espnet'
      selfattention_layer_type: 'rel_selfattn'
      use_cnn_module: False
      macaron_style: False
    length_regulator:
      channels: 256
      sampling_ratios: [1, 1, 1, 1]
    decoder:
      in_channels: 256
      cfm_params:
        sigma_min: 1e-06
        solver: 'euler'
        t_scheduler: 'cosine'
        training_cfg_rate: 0.2
        inference_cfg_rate: 0.7
        reg_loss_type: 'l1'
      estimator:
        in_channels: 672 # concat(vq_token_embedding, flow_vae_latent, spk_embed, cond)
        out_channels: 80 # flow_vae latent size
        channels: [256, 256]
        dropout: 0.0
        attention_head_dim: 64
        n_blocks: 4
        num_mid_blocks: 12
        num_heads: 8
        act_fn: 'gelu'
